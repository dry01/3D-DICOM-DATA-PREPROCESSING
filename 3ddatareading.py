# -*- coding: utf-8 -*-
"""3DDATAREADING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gsarmHR79jBb4mkRVGtL53NxyAnlml8p
"""

!pip install pydicom

import numpy as np
import pandas as pd
from skimage.io import imread
import seaborn as sns
import matplotlib.pyplot as plt

import pydicom as dicom
import os

from google.colab import drive
drive.mount('/gdrive')

data_dir = '/gdrive/My Drive/ pan/Pancreas-63502'
patients = os.listdir(data_dir)
for data in patients:
   print (data)

#print(len(os.listdir(data_dir + "Pancreas-63502")))
data_ids= next(os.walk(data_dir))[1]
print(data_ids)
print(len(data_ids))

lstFilesDCM = []                                      # create an empty list
for dirName, subdirList, fileList in os.walk(data_dir):
    for filename in fileList:
        if ".dcm" in filename.lower():                 # check whether the file's DICOM
            lstFilesDCM.append(os.path.join(dirName,filename))

RefDs = dicom.read_file(lstFilesDCM[0])
ConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(lstFilesDCM))
print(ConstPixelDims)

#ConstPixelSpacing = (float(RefDs.PixelSpacing[0]), float(RefDs.PixelSpacing[1]), float(RefDs.SliceThickness))

def return_dcm(file_path):
    
    out_dcm = {}
    for dirName, subdirList, fileList in os.walk(file_path):
        c_dcm = []
        cur_name = ""
        #dir_split = dirName.split("/")
        
        for filename in fileList:
            if ".dcm" in filename.lower():
                name = int(os.path.splitext(filename)[0])
                c_dcm.append((os.path.join(dirName,filename), name))
        if len(c_dcm) > 0:
            c_dcm = sorted(c_dcm, key = lambda t: t[1]) 
            out_dcm[cur_name] = [c[0] for c in c_dcm] 
    return out_dcm

train = RefDs

def plot_slice(slice_in):
    
    slice_in = np.squeeze(slice_in)
    plt.figure()
    plt.set_cmap(plt.bone())
    
    plt.pcolormesh(slice_in)
    plt.show()

def rotate_data(voxels, lbls, theta = None):

    if theta is None:
        theta = random.randint(-10, 10)
    vox_new = scipy.ndimage.interpolation.rotate(voxels, theta, reshape = False)
    lbl_new = scipy.ndimage.interpolation.rotate(lbls, theta, reshape = False)
    return vox_new, lbl_new

def scale_and_crop_centre(voxels, lbls):
    
    o_s = voxels.shape
    r_s = [0]*len(o_s)
    scale_factor = random.uniform(1, 1.2)
    vox_zoom = scipy.ndimage.interpolation.zoom(voxels, scale_factor, order = 1)
    lbl_zoom = scipy.ndimage.interpolation.zoom(lbls, scale_factor, order = 0)
    new_shape = vox_zoom.shape
    
    for i in range(len(o_s)):
        if new_shape[i] == 1: 
            r_s[i] = 0
            continue
        r_c = int(((new_shape[i] - o_s[i]) - 1)/2)
        r_s[i] = r_c
    r_e = [r_s[i] + o_s[i] for i in list(range(len(o_s)))]
    vox_zoom = vox_zoom[r_s[0]:r_e[0], r_s[1]:r_e[1], r_s[2]:r_e[2]]
    lbl_zoom = lbl_zoom[r_s[0]:r_e[0], r_s[1]:r_e[1], r_s[2]:r_e[2]]
    return vox_zoom, lbl_zoom

def grayscale(voxels, lbls):
  
    aug = random.randint(-10, 10)
    smp = np.random.normal(0, 1, size = np.shape(voxels))
    voxels = voxels + aug*smp
    voxels[voxels <= 0] = 0
    voxels[voxels > 500] = 500 
    return voxels, lbls

def sample_with_p(p):
  
    if random.random() < p:
        return True
    else:
        return False

def get_random_perturbation(voxels, lbls):
    
    p_rotate = 0.6
    p_scale = 0.5
    p_gray = 0.6
    cur_vox, cur_lbl = voxels, lbls
    if sample_with_p(p_rotate):
        cur_vox, cur_lbl = rotate_data(cur_vox, cur_lbl)
    if sample_with_p(p_scale):
        cur_vox, cur_lbl = scale_and_crop_centre(cur_vox, cur_lbl)
    if sample_with_p(p_gray):
        cur_vox, cur_lbl = grayscale(cur_vox, cur_lbl)
    return cur_vox, cur_lbl

INPUT_SIZE = 120 
OUTPUT_SIZE = 120
INPUT_DEPTH = 12 
OFF_IMAGE_FILL = 0 
OFF_LABEL_FILL = 0 
OUTPUT_CLASSES = 4

OUTPUT_DEPTH = 12

def get_scaled_input(data, min_i = INPUT_SIZE, min_o = OUTPUT_SIZE, depth = INPUT_DEPTH, 
                    depth_out = OUTPUT_DEPTH, image_fill = OFF_IMAGE_FILL, 
                    label_fill = OFF_LABEL_FILL, n_classes = OUTPUT_CLASSES, norm_max = 500):
    input_scale_factor = min_i/data[0].shape[0]
    output_scale_factor = min_o/data[0].shape[0]

    vox_zoom = None
    lbl_zoom = None

    if not input_scale_factor == 1:
        vox_zoom = scipy.ndimage.interpolation.zoom(data[0], input_scale_factor, order = 1) 
      
    else:
        vox_zoom = data[0]

    if not output_scale_factor == 1:
        lbl_zoom = scipy.ndimage.interpolation.zoom(data[1], output_scale_factor, order = 0) 
        
    else:
        lbl_zoom = data[1]   

    lbl_pad = label_fill*np.ones((min_o, min_o, depth_out - lbl_zoom.shape[-1]))
    lbl_zoom = np.concatenate((lbl_zoom, lbl_pad), 2)
    lbl_zoom = lbl_zoom[np.newaxis, :, :, :]
    
    vox_pad = image_fill*np.ones((min_i, min_i, depth - vox_zoom.shape[-1]))
    vox_zoom = np.concatenate((vox_zoom, vox_pad), 2)
    
    max_val = np.max(vox_zoom)
    if not np.max(vox_zoom) == 0:
        vox_zoom = vox_zoom * norm_max/np.max(vox_zoom)
        
    vox_zoom = vox_zoom[np.newaxis, :, :, :]

    vox_zoom = np.swapaxes(vox_zoom, 0, -1)
    lbl_zoom = np.swapaxes(lbl_zoom, 0, -1)
    
        
    return vox_zoom, lbl_zoom

def upscale_segmentation(lbl, shape_desired):
    
    
    scale_factor = shape_desired[0]/lbl.shape[0]
    lbl_upscale = scipy.ndimage.interpolation.zoom(lbl, scale_factor, order = 0)
    
    lbl_upscale = lbl_upscale[:, :, :shape_desired[-1]]
    if lbl_upscale.shape[-1] < shape_desired[-1]:
        pad_zero = OFF_LABEL_FILL*np.zeros((shape_desired[0], shape_desired[1], shape_desired[2] - lbl_upscale.shape[-1]))
        lbl_upscale = np.concatenate((lbl_upscale, pad_zero), axis = -1)
    return lbl_upscale

def get_label_accuracy(pred, lbl_original):
    
    pred = swap_axes(pred)
    pred_upscale = upscale_segmentation(pred, np.shape(lbl_original))
    return 100*np.sum(np.equal(pred_upscale, lbl_original))/np.prod(lbl_original.shape)

def get_mean_iou(pred, lbl_original, num_classes = OUTPUT_CLASSES, ret_full = False, reswap = False):
  
    
    
    pred = swap_axes(pred)
    if reswap:
        lbl_original = swap_axes(lbl_original)
    pred_upscale = upscale_segmentation(pred, np.shape(lbl_original))
    iou = [1]*num_classes
    for i in range(num_classes): 
        test_shape = np.zeros(np.shape(lbl_original))
        test_shape[pred_upscale == i] = 1
        test_shape[lbl_original == i] = 1
        full_sum = int(np.sum(test_shape))
        test_shape = -1*np.ones(np.shape(lbl_original))
        test_shape[lbl_original == i] = pred_upscale[lbl_original == i]
        t_p = int(np.sum(test_shape == i))
        if not full_sum == 0:
            iou[i] = t_p/full_sum
    if ret_full:
        return iou
    else: 
        return np.mean(iou)

def swap_axes(pred):
    
    pred = np.swapaxes(pred, -1, 0)
    pred = np.squeeze(pred)
    return pred

train_run = []
augment_len = 0 
for i in train:
    (vox, lbl) = get_scaled_input(i)
    train_run.append((vox, lbl))
    for j in range(augment_len):
        vox_a, lbl_a = get_random_perturbation(vox, lbl)
        train_run.append((vox_a, lbl_a))

def get_dataset_sample(data, size, no_perturb = False):
    
    x_y_data = random.sample(data, size)
    x = []
    y = []
    orig_y = []
    for entry in x_y_data:
        x_cur, y_cur = get_random_perturbation(entry[0], entry[1])
        if no_perturb:
            x_cur, y_cur = entry
        orig_y.append(np.copy(y_cur))
        x_cur, y_cur = get_scaled_input((x_cur, y_cur))
        x.append(x_cur)
        y.append(y_cur)
    return x, y, orig_y